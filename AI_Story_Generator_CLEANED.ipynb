{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbFVbGZabBFx",
    "outputId": "36d87242-8db9-42d0-87be-3e01a421ec6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Hqacbl3pbGv2"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316,
     "referenced_widgets": [
      "b0b73a7dac76488aa6f84f02c023e298",
      "c5a4863e23d54866b53c79a08bfcde94",
      "b5ba0bcfde784eadaf7f31bc38b4c011",
      "f552299063984995bc7c0c8cab448e69",
      "51cc69d927484d42b198e8f2ef118d78",
      "3870503f51ab423a9f0bbcfb70f56b20",
      "8b4ba24e8b88421bbda1fd8103bb04f2",
      "15af4acadb114910be5a56fe033091ee",
      "7bfbe4a62ea14febba624b88ab5c3f8b",
      "943654f95d824b6aa151c4dd12fbcab6",
      "b25b39c75799474393b514ed69b3e94c",
      "63f11449c926402f8b21a8de65f1f8ba",
      "1b2d06ba164341ee944cef97c0076159",
      "d5e64d7d96694f65b4486dda69bd9c6a",
      "96cd809f9bbe447bace5d06e7c8228e6",
      "2efb1503593b4e359c81b4d08e33fa69",
      "5a6c819f45d24998a312ff042a0dd61d",
      "e0b4a53e7de34e35ac2d4c9f69baf320",
      "dfe9c51eb82f4588878e457f5a7e4f2b",
      "8866781893c548e4866a1b4c63ce722d",
      "365a7ca915ad47ddb1fdf7f8d1ef0b20",
      "92e98a4abadf44bdaf19d6d5e8d4987e",
      "f2549fadcb9444338bc908193de52efd",
      "d7fb348ea4344456998b76077e8fd4c9",
      "c606d46fd6694aef86ed01f8587929d6",
      "c76da499acc34fbe8cc35f87183e879e",
      "b724e075f6364832bc1a7546fc1b9c62",
      "9b3d1941dbaf4669acf6fea1a7a2a07a",
      "86710d3fbd6b465db9f23b5929ef0ab1",
      "4f16970eadea4043805c74312728583c",
      "73ed3f66e8b04679891940d3da560972",
      "b73d292c6d6d4e939565fe22afe4ff99",
      "427b324ef58b4d8cb00daec1a736a07c",
      "b2344f1273bd4fbe9209bb92be76ebac",
      "cf034e5b53b94fa7a5e3d510c9ec0f64",
      "559e38981fd749b59e2eccc8963af775",
      "7a198f0cc12343099e6a95944a26d537",
      "1c98a32fd59f47199e28c0c7266cfb55",
      "e09fd8703e1045ca9242b7e2bdcef4d1",
      "9bf3bb6f0dec44c18e3684300a802e5c",
      "5af1531b30304a54904a4983a6e704bd",
      "b751d913d9d34c4ea4859b7890d8d1d8",
      "de0df10c26ed48fbb5ad967dd81b31a5",
      "e426c6a0204d4dddb500ac8be058f022",
      "f59134b40af944b0a00b01a113b9d857",
      "810b3ac6f7f44e3f9657c1fc45cd13db",
      "c0505ac0e2e0440882728dcb47c54b0b",
      "de736cea42684ce0b8ce3c09a957f6e0",
      "acf478215b7843f5bf96912f78e6af7f",
      "1ba30d94402a4c62a82ce1a4e5ad4ffa",
      "8e630ead201f41f0a9c7827fec9d1793",
      "8e219ad249c34882b82b4d9f73a0d3b1",
      "8b8e8a7e743c46bab2bbd319ad017eea",
      "df422c4804744e9889f6111f92e48793",
      "86b655305965405293e0193a129daea3",
      "bd79af23ddb24d999db8dfdd812b0d0d",
      "d7aef24d5e9c4e99889b795e2cb57de8",
      "269b19280108414b83fa5613936c3351",
      "a72e445eb6df4da099db3285a5407543",
      "fff3b91f95254eb88d307e84187a8cad",
      "4c46eac38e584505af0b6492a574b421",
      "738179c0f7464044a9e64ff1d23141d1",
      "da81da41cd45412c8688a12ca97d0535",
      "1cb854b871ba4618a8837961faecd12f",
      "81f32fcce6734f51bc16aa8eb2b03039",
      "09467e99bafa4e4ba950f39bc46f6a32"
     ]
    },
    "id": "jiR1Lw_ne_Z2",
    "outputId": "a8d25104-030f-4159-bc82-7ad88571f63c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b73a7dac76488aa6f84f02c023e298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "instruct_pipeline.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/databricks/dolly-v2-3b:\n",
      "- instruct_pipeline.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f11449c926402f8b21a8de65f1f8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2549fadcb9444338bc908193de52efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2344f1273bd4fbe9209bb92be76ebac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/450 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59134b40af944b0a00b01a113b9d857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd79af23ddb24d999db8dfdd812b0d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨ Give a short story idea: A character wakes up on the forest floor with no memory of how they got there. All they see besides trees and underbrush is a slip of paper with one word: Run\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"databricks/dolly-v2-3b\", device_map=\"auto\", trust_remote_code=True)\n",
    "idea = input(\"✨ Give a short story idea: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-A9_6D4cfX0v",
    "outputId": "12aba559-d347-444d-dcac-319b58554b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Generated Story:\n",
      "\n",
      "I was in the forest, all alone, when I saw the word run. I picked up the paper and slowly made my way to the highway. The word run was my ticket to a normal life, one full of coffee and croissants, and a faraway place called work. My co-workers thought I was crazy, but I was filled with excitement at the chance to escape. My escape from the world of puzzles and people who kept me guessing. I'd spent years working to crack a particularly hard code. The one I couldn't crack was the one keeping me locked up. \n",
      "\n",
      "As I rode the freeway, I laughed at the lies my co-workers fed me. I laughed at the puzzles I created for myself. I laughed at how stupid they were. I laughed until my laughter turned into a jog. I'd run all my life, and now I was finally running away. I was finally free.\n"
     ]
    }
   ],
   "source": [
    "story_input = f\"\"\"Imagine you're a creative storyteller. Based on the theme, craft a compelling short story (about 300 words):\n",
    "\n",
    "\"{idea}\"\n",
    "\n",
    "Your story should have interesting characters, a setting, and a twist that captures attention.\"\"\"\n",
    "\n",
    "result = generator(\n",
    "    story_input,\n",
    "    max_new_tokens=330,\n",
    "    do_sample=True,\n",
    "    temperature=0.9\n",
    ")[0][\"generated_text\"]\n",
    "\n",
    "print(\"\\n Generated Story:\\n\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
